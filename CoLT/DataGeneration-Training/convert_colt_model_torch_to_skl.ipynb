{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\anaconda3\\envs\\codenames\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "from statistics import mean\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import accumulate\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import datetime\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(torch.nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        outputs = torch.sigmoid(self.linear(x))\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded torch model:  data\\score_torch_model-Linear-Final-36-1-35v-2022-11-04-09-41-23.pt\n"
     ]
    }
   ],
   "source": [
    "#Load torch model and convert it to sklearn LinearRegression Model\n",
    "loadname = r'data\\score_torch_colt_model.pt'\n",
    "torch_model = torch.load(loadname)\n",
    "print('Loaded torch model: ', loadname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch weight 0 = -4.695091724395752\n",
      "Torch weight 1 = -1.8543732166290283\n",
      "Torch weight 2 = -9.739892959594727\n",
      "Torch weight 3 = 1.7059537172317505\n",
      "Torch weight 4 = -1.6369715929031372\n",
      "Torch weight 5 = 0.00658305361866951\n",
      "Torch weight 6 = -5.551140308380127\n",
      "Torch weight 7 = 1.941271185874939\n",
      "Torch weight 8 = -0.4041709303855896\n",
      "Torch weight 9 = 0.8298859596252441\n",
      "Torch weight 10 = -4.566517353057861\n",
      "Torch weight 11 = 2.274085521697998\n",
      "Torch weight 12 = 0.49170276522636414\n",
      "Torch weight 13 = 1.4675524234771729\n",
      "Torch weight 14 = -3.797506093978882\n",
      "Torch weight 15 = 2.7123939990997314\n",
      "Torch weight 16 = 1.1092449426651\n",
      "Torch weight 17 = 1.9446426630020142\n",
      "Torch weight 18 = -2.891756772994995\n",
      "Torch weight 19 = 3.0217623710632324\n",
      "Torch weight 20 = 1.6080971956253052\n",
      "Torch weight 21 = 1.9599496126174927\n",
      "Torch weight 22 = -2.732170820236206\n",
      "Torch weight 23 = 2.9600441455841064\n",
      "Torch weight 24 = 1.7915613651275635\n",
      "Torch weight 25 = 2.1286046504974365\n",
      "Torch weight 26 = -2.573078155517578\n",
      "Torch weight 27 = 2.9495534896850586\n",
      "Torch weight 28 = 1.8810383081436157\n",
      "Torch weight 29 = 2.1098809242248535\n",
      "Torch weight 30 = -1.805972695350647\n",
      "Torch weight 31 = 2.4437270164489746\n",
      "Torch weight 32 = 1.1204999685287476\n",
      "Torch weight 33 = 1.2955148220062256\n",
      "Torch weight 34 = -1.1355340480804443\n",
      "Torch weight 35 = 1.5280150175094604\n"
     ]
    }
   ],
   "source": [
    "#Create scikit-learn model\n",
    "skl_model = LinearRegression(fit_intercept=False)\n",
    "skl_model.coef_ = np.zeros(36)\n",
    "skl_model.intercept_ = 0\n",
    "#Cycle through all the coefficients from the torch model\n",
    "\n",
    "for i in range(36):\n",
    "    x = torch.zeros(36)\n",
    "    x[i] = 1.0\n",
    "    w = torch_model.linear(x).item()\n",
    "    skl_model.coef_[i] = w\n",
    "    print(f'Torch weight {i} = {skl_model.coef_[i]}')\n",
    "\n",
    "#That should do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT CLOSE: ty= -0.11406326293945312  and sy= [-0.11406175]\n",
      "NOT CLOSE: ty= -0.044322967529296875  and sy= [-0.04432438]\n",
      "NOT CLOSE: ty= 0.017177581787109375  and sy= [0.01717724]\n",
      "NOT CLOSE: ty= 0.058228492736816406  and sy= [0.05822739]\n",
      "NOT CLOSE: ty= -0.16495037078857422  and sy= [-0.16494814]\n",
      "NOT CLOSE: ty= 0.07100105285644531  and sy= [0.07099969]\n",
      "NOT CLOSE: ty= 0.09995651245117188  and sy= [0.09995489]\n",
      "NOT CLOSE: ty= -0.029485702514648438  and sy= [-0.02948513]\n",
      "Checked 1000 values. 8 were not close.\n"
     ]
    }
   ],
   "source": [
    "#Let's verify that things work the same - SANITY CHECK\n",
    "not_close = 0\n",
    "N = 1000\n",
    "for i in range(N):\n",
    "    x = torch.rand(36)\n",
    "    ty = torch_model.linear(x).item()\n",
    "    xn = x.numpy().reshape(1,-1)\n",
    "    sy = skl_model.predict(xn)\n",
    "    if not np.isclose(ty,sy):\n",
    "        print('NOT CLOSE: ty=', ty, ' and sy=', sy)#, 'input was X=', x)\n",
    "        not_close += 1\n",
    "\n",
    "print(f'Checked {N} values. {not_close} were not close.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data\\\\sklinear36model-nobias-11-04-2022.joblib']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save out the sk_learn model, using joblib\n",
    "save_name = r'data\\sklinear_colt_model.joblib'\n",
    "joblib.dump(skl_model, save_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('codenames')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "1882dddfafd0aae53b623b462ff1a3461b0f64b7a3f997ab6859ec6f2a8bb41f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
